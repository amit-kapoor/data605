---
title: "Data605_Assignment4"
author: "Amit Kapoor"
date: "2/20/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem set 1

## 1. In this problem, we'll verify using R that SVD and Eigenvalues are related as worked out in the weekly module. Given a 3x2 matrix A

$A = \left( \begin{matrix} 1&2&3 \\ -1&0&4 \end{matrix} \right)$

## write code in R to compute X = A$\mathbf{A}^\intercal$ and Y = $\mathbf{A}^\intercal$A. Then, compute the eigenvalues and eigenvectors of X and Y using the built-in commans in R. Then, compute the left-singular, singular values, and right-singular vectors of A using the svd command. Examine the two sets of singular vectors and show that they are indeed eigenvectors of X and Y. In addition, the two non-zero eigenvalues (the 3rd value will be very close to zero, if not zero) of both X and Y are the same and are squares of the non-zero singular values of A. Your code should compute all these vectors and scalars and store them in variables. Please add enough comments in your code to show me how to interpret your steps.




```{r matrix-A, echo=TRUE}

# define matrix A
A <- matrix(cbind(1,2,3,-1,0,4), byrow = T, ncol = 3)
A
```

```{r compute-X, echo=TRUE}

# compute X using t() function for matrix transpose
X <- A %*% t(A)
X
```

```{r compute-Y, echo=TRUE}

# compute Y
Y <- t(A) %*% A 
Y
```

### compute the eigenvalues and eigenvectors of X and Y using the built-in commans in R

```{r eigen-values-X, echo=TRUE}

eigen_X <- eigen(X)

# eigen values of X
eigen_X$values
```

```{r eigen-vectors-X, echo=TRUE}

# eigen vectors of X
eigen_X$vectors

```


```{r eigen-values-Y, echo=TRUE}

eigen_Y <- eigen(Y)
# eigen values of Y
eigen_Y$values
```

```{r eigen-vectors-Y, echo=TRUE}

# eigen vectors of Y
eigen_Y$vectors
```



### compute the left-singular, singular values, and right-singular vectors of A using the svd command.


```{r svd-A, echo=TRUE}

# svd() function
# d -> vector containing the singular values of given matrix
# u -> matrix whose columns contain the left singular vectors of given marix
# v -> matrix whose columns contain the right singular vectors of given marix


svd_A <- svd(A)
svd_A
```



### Examine the two sets of singular vectors and show that they are indeed eigenvectors of X and Y. 

```{r list-x-ls, echo=TRUE}
list(eigen_X$vectors, svd_A$u)
```



```{r compare-x-ls-1, echo=TRUE}

# comparing the left singular value svd_A$u with eigen_X
round(svd(A)$u,4) == round(eigen_X$vectors,4)
```

```{r compare-x-ls-2, echo=TRUE}

u_rounded <- round(svd(A)$u,4)

# multiply first column of left singular by -1
u_rounded[,1] = -u_rounded[,1]

round(u_rounded,4) == round(eigen_X$vectors,4)
```


```{r list-y-rs, echo=TRUE}
list(eigen_Y$vectors, svd_A$v)
```


```{r compare-y-rs-1, echo=TRUE}

# comparing the left singular value svd_A$u with eigen_Y
round(svd(A)$v,4) == round(eigen_Y$vectors[,-3],4)
```

```{r compare-y-rs-2, echo=TRUE}

v_rounded <- round(svd(A)$v,4)
# multiply first column of right singular by -1
v_rounded[,1] = -v_rounded[,1]
# compare values
round(v_rounded,4) == round(eigen_Y$vectors[,-3],4)
```


### In addition, the two non-zero eigenvalues (the 3rd value will be very close to zero, if not zero) of both X and Y are the same and are squares of the non-zero singular values of A.


```{r svd-A-square, echo=TRUE}
round(svd_A$d^2,4) 
```

```{r eigen-X-val, echo=TRUE}
round(eigen_X$values,4)
```

```{r eigen-Y-val, echo=TRUE}

# using format function to not display eigen_Y$values in scientific notation
eigen_Y$values <- format(eigen_Y$values, scientific=F)
# convert the values from string to numeric values and then round off
round(as.numeric(eigen_Y$values), 4)
```

### Hence we see the 3rd value is zero (after rounded off else close to 0) for eigen_Y values and it's first 2 are equal to eigen_X values and squares of the non-zero singular values of A.


# Problem set 2

## Using the procedure outlined in section 1 of the weekly handout, write a function to compute the inverse of a well-conditioned full-rank square matrix using co-factors. In order to compute the co-factors, you may use built-in commands to compute the determinant. Your function should have the following signature:
B = myinverse(A)

## where A is a matrix and B is its inverse and AxB = I. The off-diagonal elements of I should be close to zero, if not zero. Likewise, the diagonal elements should be close to 1, if not 1. Small numerical precision errors are acceptable but the function myinverse should be correct and must use co-factors and determinant of A to compute the inverse. 

```{r myinverse, echo=TRUE}

myinverse <- function(A) {
  
  # get rows and columns
  rows <- nrow(A)
  cols <- ncol(A)
  
  # check if given matrix is a square matrix and full rank
  if(rows!=cols | qr(A)$rank != dim(A)[1]) {
    return("Cant move forward. A should be square and full rank matrix.")
    
  } else {
    # create an empty co-factors matrix
    cofactors <- matrix(rep(0, length(A)), nrow = rows, ncol = cols)
    
    for(i in 1:rows) {
      for(j in 1:cols) {
        # M is a matrix with row i and col j excluded
        M <- A[-i,-j]
        # populate co-factors matrix
        cofactors[i,j] <- (-1)^(i+j) * det(M)
      }
    }
    
    # return inverse of matrix
    B <- t(cofactors)/det(A)
    return(B)
  }
}
```

### Test with non square matrix

```{r test-1, echo=TRUE}
A <- matrix(cbind(1,2,3,4,5,6), nrow = 2, byrow = T)
myinverse(A)
```

### Test with square matrix

```{r test-2, echo=TRUE}
A = matrix(c(1,8,3,-1,9,4,6,7,9), nrow = 3, byrow = T)
B <- myinverse(A)
B
```

### Product of A and B should be 1 or close to 1
```{r product-A-B, echo=TRUE}
round(A %*% B, 4)
```

### Hence AXB = I

